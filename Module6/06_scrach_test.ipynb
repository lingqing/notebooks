{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/andy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "root_dir = './data/MNIST/'\n",
    "train_set = torchvision.datasets.MNIST(root=root_dir, train=True, download=True)\n",
    "images = train_set.data.numpy().astype(np.float32)/255\n",
    "labels = train_set.targets.numpy()\n",
    "n=len(images)\n",
    "\n",
    "eights=[images[i] for i in range(n) if labels[i]==8]\n",
    "ones=[images[i] for i in range(n) if labels[i]==1]\n",
    "\n",
    "bs = 64\n",
    "\n",
    "l8 = np.array(0)\n",
    "eights_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), torch.from_numpy(l8.astype(np.int64))] for e in eights]\n",
    "l1 = np.array(1)\n",
    "ones_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), torch.from_numpy(l1.astype(np.int64))] for e in ones]\n",
    "train_dataset = eights_dataset[1000:] + ones_dataset[1000:]\n",
    "test_dataset = eights_dataset[:1000] + ones_dataset[:1000]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "    batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "    batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        # fill the missing entries below\n",
    "        # self.lsfm   = nn.LogSoftmax(dim=1)\n",
    "        self.feature_layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),\n",
    "            ('conv2', nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, padding=1)),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=2)),\n",
    "        ]))\n",
    "        self.fc = nn.Linear(in_features=32*7*7, out_features=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # implement your network here, use F.max_pool2d, F.log_softmax and do not forget to flatten your vector\n",
    "        # x = self.conv1(x)\n",
    "        #\n",
    "        # Your code here\n",
    "        #\n",
    "        #\n",
    "        # x = F.max_pool2d(x, kernel_size=2)  # (N, C=8, W=14, H=14)\n",
    "        # x = F.conv2d(x, input_channel=8, output_channel=32, kernel_size=3, padding=1) #(N, C=32, W=14, H=14)\n",
    "        # x = F.max_pool2d(x, kernel_size=2)  # (N, C=32, W=7, H=7)\n",
    "        # x = F.linear(x.reshape(x.shape[0], -1), input_features=32*7*7, output_features=128)\n",
    "        # x = self.fc(x) #(N, 2)\n",
    "        x = self.feature_layers(x)\n",
    "        x = self.fc(x.reshape(x.shape[0], -1))\n",
    "        x = F.log_softmax(x, dim=1) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
    "    model.train(True)\n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    acc_train = np.zeros(n_epochs)\n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "            #\n",
    "            #\n",
    "            # Your code here\n",
    "            #\n",
    "            #\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = loss_fn(outputs, labels.to(device))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.cpu()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc_es = (preds.cpu() == labels)\n",
    "            running_corrects = torch.sum(acc_es).cpu()\n",
    "            size += bs\n",
    "        epoch_loss = running_loss.item() / size\n",
    "        epoch_acc = running_corrects.item() / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_class = classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0103 Acc: 0.0026\n",
      "Train - Loss: 0.0094 Acc: 0.0030\n",
      "Train - Loss: 0.0085 Acc: 0.0031\n",
      "Train - Loss: 0.0076 Acc: 0.0030\n",
      "Train - Loss: 0.0067 Acc: 0.0030\n",
      "Train - Loss: 0.0058 Acc: 0.0029\n",
      "Train - Loss: 0.0049 Acc: 0.0029\n",
      "Train - Loss: 0.0043 Acc: 0.0029\n",
      "Train - Loss: 0.0037 Acc: 0.0029\n",
      "Train - Loss: 0.0032 Acc: 0.0029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# choose the appropriate loss\n",
    "loss_fn = nn.NLLLoss()\n",
    "# your SGD optimizer\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(conv_class.parameters(), lr=learning_rate)\n",
    "# and train for 10 epochs\n",
    "l_t, a_t = train(conv_class,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "            \n",
    "        bs = labels.size(0)\n",
    "        #\n",
    "        # Your code here\n",
    "        #\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "        \n",
    "        running_loss += loss.cpu()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc_es = (preds.cpu() == labels)\n",
    "        running_corrects += torch.sum(acc_es).cpu()\n",
    "            \n",
    "        size += bs\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 0.0033 Acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "test(conv_class, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in conv_class.children():\n",
    "    T_w = m.weight.data.numpy()\n",
    "    T_b = m.bias.data.numpy()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
