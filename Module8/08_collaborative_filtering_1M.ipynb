{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKEoXRSzUUCv"
   },
   "source": [
    "# Collaborative filtering: refactoring the code\n",
    "-----\n",
    "\n",
    "In this practical, you will need to refactor the code seen during the lesson in order to deal with the [Movielens 1M Dataset](https://grouplens.org/datasets/movielens/1m/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OeHGO4qbUUC4"
   },
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frj5rX9wUUC_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2 compat\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "# this line need to be changed:\n",
    "data_folder = '/home/andy/00_workspace/dl/data/08/content/'\n",
    "\n",
    "\n",
    "ML_1M_URL = \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "ML_1M_FILENAME = op.join(data_folder,ML_1M_URL.rsplit('/', 1)[1])\n",
    "ML_1M_FOLDER = op.join(data_folder,'ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utzHaMDsV1Bq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not op.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "if not op.exists(ML_1M_FILENAME):\n",
    "    print('Downloading %s to %s...' % (ML_1M_URL, ML_1M_FILENAME))\n",
    "    urlretrieve(ML_1M_URL, ML_1M_FILENAME)\n",
    "\n",
    "if not op.exists(ML_1M_FOLDER):\n",
    "    print('Extracting %s to %s...' % (ML_1M_FILENAME, ML_1M_FOLDER))\n",
    "    ZipFile(ML_1M_FILENAME).extractall(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHgLg4jBUUDp"
   },
   "source": [
    "## 2. Data analysis and formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlGyPSBpUUDt"
   },
   "source": [
    "As in the lesson, we start by loading the data with [Python Data Analysis Library](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qk6Vp83IV1Bv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  ratings  timestamp\n",
       "0        1     1193        5  978300760\n",
       "1        1      661        3  978302109\n",
       "2        1      914        3  978301968\n",
       "3        1     3408        4  978300275\n",
       "4        1     2355        5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_ratings = pd.read_csv(op.join(ML_1M_FOLDER, 'ratings.dat'), sep='::',\n",
    "                          names=[\"user_id\", \"item_id\", \"ratings\", \"timestamp\"],engine='python')\n",
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDPeRguMV1Bz",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id                           item_name\n",
       "0       1                    Toy Story (1995)\n",
       "1       2                      Jumanji (1995)\n",
       "2       3             Grumpier Old Men (1995)\n",
       "3       4            Waiting to Exhale (1995)\n",
       "4       5  Father of the Bride Part II (1995)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_movies_names = []\n",
    "list_item_ids = []\n",
    "with open(op.join(ML_1M_FOLDER, 'movies.dat'), encoding='ISO-8859-1') as fp: # 'movurllib.request import urlretrieve\n",
    "    for line in fp:\n",
    "        items = line.split('::')\n",
    "        list_item_ids.append(items[0])\n",
    "        list_movies_names.append(items[1])\n",
    "# except ImportError:  # Python 2 compat\n",
    "#     from urllib import urlretrieve\n",
    "\n",
    "# # this line need to be changed:\n",
    "# # data_folder = '/content/'\n",
    "\n",
    "\n",
    "# ML_1M_URL = \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "# ML_1M_FILENAME = op.join(data_folder,ML_1M_URL.re.split('::')[1])\n",
    "        \n",
    "movies_names = pd.DataFrame(list(zip(list_item_ids, list_movies_names)), \n",
    "               columns =['item_id', 'item_name']) \n",
    "movies_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nVdjC0IV1B3"
   },
   "source": [
    "Here we add the title of the movies to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21gIXEkXV1B4"
   },
   "outputs": [],
   "source": [
    "movies_names['item_id']=movies_names['item_id'].astype(int)\n",
    "all_ratings['item_id']=all_ratings['item_id'].astype(int)\n",
    "all_ratings = all_ratings.merge(movies_names,on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XJlXE1mV1B8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  ratings  timestamp  \\\n",
       "0        1     1193        5  978300760   \n",
       "1        2     1193        5  978298413   \n",
       "2       12     1193        4  978220179   \n",
       "3       15     1193        4  978199279   \n",
       "4       17     1193        5  978158471   \n",
       "\n",
       "                                item_name  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)  \n",
       "3  One Flew Over the Cuckoo's Nest (1975)  \n",
       "4  One Flew Over the Cuckoo's Nest (1975)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enyJuYhUUUEL"
   },
   "source": [
    "The dataframe `all_ratings` contains all the raw data for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M7-jinQUUEO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of entries\n",
    "len(all_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofVcE781UUEa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     3.581564e+00\n",
       "std      1.117102e+00\n",
       "min      1.000000e+00\n",
       "25%      3.000000e+00\n",
       "50%      4.000000e+00\n",
       "75%      4.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: ratings, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings['ratings'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCdV2qzMUUEk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings['ratings'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zU9vARwJUUEs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     3.024512e+03\n",
       "std      1.728413e+03\n",
       "min      1.000000e+00\n",
       "25%      1.506000e+03\n",
       "50%      3.070000e+03\n",
       "75%      4.476000e+03\n",
       "max      6.040000e+03\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings['user_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1QoS71CUUE7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n"
     ]
    }
   ],
   "source": [
    "# number of unique users\n",
    "total_user_id = len(all_ratings['user_id'].unique())\n",
    "print(total_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Az4KDFgV1CQ"
   },
   "source": [
    "We see that as in the lesson, the users seem to be indexed from 1 to 6040. Let's check that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pj8ZAzmIV1CQ"
   },
   "outputs": [],
   "source": [
    "list_user_id = list(all_ratings['user_id'].unique())\n",
    "list_user_id.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9omI-cwV1CT"
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(list_user_id):\n",
    "    if j != i+1:\n",
    "        print(i,j) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-LytszyV1CV"
   },
   "source": [
    "We create a new column `user_num` to get an index from 0 to 6039 for users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jE6WVgT-V1CV"
   },
   "outputs": [],
   "source": [
    "all_ratings['user_num'] = all_ratings['user_id'].apply(lambda x :x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HldBddZV1CY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_name</th>\n",
       "      <th>user_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  ratings  timestamp  \\\n",
       "0        1     1193        5  978300760   \n",
       "1        2     1193        5  978298413   \n",
       "2       12     1193        4  978220179   \n",
       "3       15     1193        4  978199279   \n",
       "4       17     1193        5  978158471   \n",
       "\n",
       "                                item_name  user_num  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)         0  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)         1  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)        11  \n",
       "3  One Flew Over the Cuckoo's Nest (1975)        14  \n",
       "4  One Flew Over the Cuckoo's Nest (1975)        16  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0OThRYhV1Cb"
   },
   "source": [
    "We now look at movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3gfokbNUUFH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     1.865540e+03\n",
       "std      1.096041e+03\n",
       "min      1.000000e+00\n",
       "25%      1.030000e+03\n",
       "50%      1.835000e+03\n",
       "75%      2.770000e+03\n",
       "max      3.952000e+03\n",
       "Name: item_id, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings['item_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ncInsk_V1Cg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706\n"
     ]
    }
   ],
   "source": [
    "# number of unique rated items\n",
    "total_item_id = len(all_ratings['item_id'].unique())\n",
    "print(total_item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gGu2LjiV1Ci"
   },
   "source": [
    "Here there is a clear problem: there are 3706 different movies but the range of `item_id` starts at 1 and ends at 3952. So there are gaps, so the first thing you will need to do is to create a new column `item_num` so that all movies are indexed from 0 to 3705."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Zs7e-pyV1Cj"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# your code here\n",
    "#\n",
    "# item_id2num_map = pd.DataFrame(all_ratings['item_id'].unique(), columns=['item_id']).sort_values(by=['item_id'])\n",
    "# item_id2num_map['item_num'] = range(len(item_id2num_map))\n",
    "\n",
    "item_id2num_map = all_ratings['item_id'].unique()\n",
    "item_num2id_map = np.arange(max(item_id2num_map)+1)\n",
    "for i,j in enumerate(item_id2num_map):\n",
    "    item_num2id_map[j] = i\n",
    "    \n",
    "all_ratings['item_num'] = all_ratings['item_id'].apply(lambda x: item_num2id_map[x])\n",
    "\n",
    "del item_id2num_map, item_num2id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "weNJOlzcV1Cl"
   },
   "source": [
    "This function will verify that your result is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktctMT12V1Cl"
   },
   "outputs": [],
   "source": [
    "def check_ratings_num(df):\n",
    "    item_num = set(df['item_num'])\n",
    "    if item_num == set(range(len(item_num))):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4w1XQnfV1Cp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_ratings_num(all_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYa43L6EV1Cr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_name</th>\n",
       "      <th>user_num</th>\n",
       "      <th>item_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  ratings  timestamp  \\\n",
       "0        1     1193        5  978300760   \n",
       "1        2     1193        5  978298413   \n",
       "2       12     1193        4  978220179   \n",
       "3       15     1193        4  978199279   \n",
       "4       17     1193        5  978158471   \n",
       "\n",
       "                                item_name  user_num  item_num  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)         0         0  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)         1         0  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)        11         0  \n",
       "3  One Flew Over the Cuckoo's Nest (1975)        14         0  \n",
       "4  One Flew Over the Cuckoo's Nest (1975)        16         0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur4bjuniUUFj"
   },
   "source": [
    "Now we will split the data in _train_, _val_ and _test_ be using a pre-defined function from [scikit-learn](http://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT5oxhoGUUFm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings_trainval, ratings_test = train_test_split(all_ratings, test_size=0.1, random_state=42)\n",
    "\n",
    "ratings_train, ratings_val = train_test_split(ratings_trainval, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7JF-d05UUGc"
   },
   "source": [
    "## 3. The model\n",
    "\n",
    "We will now modify a bit the `FactorizationModel` class seen during the lesson. Internally, we will still use the `Model_dot` but now we use the PyTorch dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tsrfFi1QUUGd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dYlOkCzV1C0"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3OnBFlOV1C2"
   },
   "outputs": [],
   "source": [
    "def df_2_tensor(df, device):\n",
    "    # return a triplet user_num, item_num, rating from the dataframe\n",
    "    user_num = np.asarray(df['user_num'])\n",
    "    item_num = np.asarray(df['item_num'])\n",
    "    rating = np.asarray(df['ratings'])\n",
    "    return torch.from_numpy(user_num).to(device), torch.from_numpy(item_num).to(device), torch.from_numpy(rating).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2UUX0GDV1C4"
   },
   "source": [
    "Below, we construct 3 tensors containing the `user_num`, `item_num` and `rating` for the training set. All tensors have the same shape so that `train_user_num[i]` watched `train_item_num[i]` and gave a rating of `train_rating[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY7lG3M_V1C5"
   },
   "outputs": [],
   "source": [
    "train_user_num, train_item_num, train_rating = df_2_tensor(ratings_train,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SY39426KV1C7"
   },
   "source": [
    "We now do the same thing for the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1bjHQExV1C8"
   },
   "outputs": [],
   "source": [
    "val_user_num, val_item_num, val_rating = df_2_tensor(ratings_val,device)\n",
    "test_user_num, test_item_num, test_rating = df_2_tensor(ratings_test,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpkKu7PVUUGp"
   },
   "source": [
    "The code below is taken from the lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB6_y1nMUUGq"
   },
   "outputs": [],
   "source": [
    "class ScaledEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "    Embedding layer that initialises its values\n",
    "    to using a normal variable scaled by the inverse\n",
    "    of the embedding dimension.\n",
    "    \"\"\"\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weight.data.normal_(0, 1.0 / self.embedding_dim)\n",
    "        if self.padding_idx is not None:\n",
    "            self.weight.data[self.padding_idx].fill_(0)\n",
    "\n",
    "\n",
    "class ZeroEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "    Used for biases.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weight.data.zero_()\n",
    "        if self.padding_idx is not None:\n",
    "            self.weight.data[self.padding_idx].fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktXRW3-4UUGt"
   },
   "outputs": [],
   "source": [
    "class DotModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim=32):\n",
    "        \n",
    "        super(DotModel, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.user_embeddings = ScaledEmbedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim)\n",
    "        self.user_biases = ZeroEmbedding(num_users, 1)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1)\n",
    "                \n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        #\n",
    "        # your code\n",
    "        #\n",
    "        user_emb = self.user_embeddings(user_ids) + self.user_biases(user_ids) # (M, emb=3)\n",
    "        item_emb = self.item_embeddings(item_ids) + self.item_biases(item_ids) # (N, emb=3)\n",
    "        return user_emb.mul(item_emb).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlbbwU1ze5d7"
   },
   "outputs": [],
   "source": [
    "net = DotModel(total_user_id,total_item_id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysX9Q9pxiMG4"
   },
   "source": [
    "Now test your network on a small batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I20UhBLZjBEs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0026,  0.0067, -0.0038, -0.0017,  0.0102], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicitions = net(train_user_num[:5], train_item_num[:5])\n",
    "predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sqlTLCyiwzl"
   },
   "outputs": [],
   "source": [
    "def regression_loss(predicted_ratings, observed_ratings):\n",
    "    return ((observed_ratings - predicted_ratings) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ins38kThjNl0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.9758, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = regression_loss\n",
    "loss = loss_fn(predicitions, train_rating[:5])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYpYDeK0V1DN"
   },
   "source": [
    "Now you need to construct a dataset and a dataloader. For this, you can define a first function taking as arguments the tensors defined above and returning a list; then a second function taking as argument a dataset, the batchsize and a boolean for the shuffling. We will not use anymore the functions `shuffle` and `minibatch` used in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1VFUdHtV1DO"
   },
   "outputs": [],
   "source": [
    "def tensor_2_dataset(user,item,rating):\n",
    "    # your code here\n",
    "    # input_list = torch.cat((user.unsqueeze(1),item.unsqueeze(1), rating.unsqueeze(1)),dim=1)\n",
    "    # output_list = rating\n",
    "    dataset = torch.utils.data.TensorDataset(user, item, rating)\n",
    "    return dataset\n",
    "\n",
    "def make_dataloader(dataset,bs,shuffle):\n",
    "    # your code here\n",
    "    # index = np.arange(len(dataset[0]))\n",
    "    # # random index for shuffling\n",
    "    # if shuffle:\n",
    "    #     np.random.shuffle(index)\n",
    "    # # shuffle the dataset\n",
    "    # bs_cnt = (len(index)-1) // bs +1\n",
    "    # for i in range(bs_cnt):\n",
    "    #     if i != bs_cnt-1:\n",
    "    #         yield (dataset[0][index[i*bs:(i+1)*bs]], dataset[1][index[i*bs:(i+1)*bs]] )\n",
    "    #     else:\n",
    "    #         yield (dataset[0][index[i*bs:]], dataset[1][index[i*bs:]] )\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-Y4ruIPV1DS"
   },
   "outputs": [],
   "source": [
    "train_dataset = tensor_2_dataset(train_user_num,train_item_num, train_rating)\n",
    "val_dataset = tensor_2_dataset(val_user_num,val_item_num,val_rating)\n",
    "test_dataset = tensor_2_dataset(test_user_num, test_item_num, test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXvR2apHV1DU"
   },
   "outputs": [],
   "source": [
    "train_dataloader = make_dataloader(train_dataset,1024,True)\n",
    "val_dataloader = make_dataloader(val_dataset,1024, False)\n",
    "test_dataloader = make_dataloader(test_dataset,1024,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wz1h-gG-V1DX"
   },
   "source": [
    "Here you need to modify the code seen during the lesson:\n",
    " - remove the batch_size in the init\n",
    " - the fit function should now take as argument a dataloader for the training and a dataloader for the validation. AT the end of each epoch, you run the test method on the validation set. Then you print both the loss on the training set and on the validation set to see if you are overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ekPPr7SUUG7"
   },
   "outputs": [],
   "source": [
    "class FactorizationModel(object):\n",
    "    \n",
    "    def __init__(self, embedding_dim=32, n_iter=10, l2=0.0,\n",
    "                 learning_rate=1e-2, device=device, net=None, num_users=None,\n",
    "                 num_items=None,random_state=None):\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._n_iter = n_iter\n",
    "        self._learning_rate = learning_rate\n",
    "        self._l2 = l2\n",
    "        self._device = device\n",
    "        self._num_users = num_users\n",
    "        self._num_items = num_items\n",
    "        self._net = net\n",
    "        self._optimizer = None\n",
    "        self._loss_func = None\n",
    "        self._random_state = random_state or np.random.RandomState()\n",
    "             \n",
    "        \n",
    "    def _initialize(self):\n",
    "        if self._net is None:\n",
    "            self._net = DotModel(self._num_users, self._num_items, self._embedding_dim).to(self._device)\n",
    "        \n",
    "        self._optimizer = optim.Adam(\n",
    "                self._net.parameters(),\n",
    "                lr=self._learning_rate,\n",
    "                weight_decay=self._l2\n",
    "            )\n",
    "        \n",
    "        self._loss_func = regression_loss\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def _initialized(self):\n",
    "        return self._optimizer is not None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return _repr_model(self)\n",
    "    \n",
    "    def fit(self, dataloader, val_dataloader, verbose=True):       \n",
    "        if not self._initialized:\n",
    "            self._initialize()\n",
    "            \n",
    "        for epoch_num in range(self._n_iter):\n",
    "            epoch_loss = 0.0\n",
    "            self._net.train(True)\n",
    "            minibatch_num = 0\n",
    "            #\n",
    "            # your code\n",
    "            #\n",
    "            for users, items, label in dataloader:\n",
    "                output = self._net(users.to(self._device), items.to(self._device))\n",
    "                loss = self._loss_func(output, label)\n",
    "                \n",
    "                self._optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.cpu().item()\n",
    "                minibatch_num += 1\n",
    "                \n",
    "            \n",
    "            epoch_loss = epoch_loss / (minibatch_num)\n",
    "            loss_test = self.test(val_dataloader)\n",
    "\n",
    "            if verbose:\n",
    "                print('Epoch {}: loss_train {}, loss_val {}'.format(epoch_num, epoch_loss,loss_test))\n",
    "        \n",
    "            if np.isnan(epoch_loss) or epoch_loss == 0.0:\n",
    "                raise ValueError('Degenerate epoch loss: {}'\n",
    "                                 .format(epoch_loss))\n",
    "    \n",
    "    \n",
    "    def test(self,dataloader, verbose = False):\n",
    "        self._net.train(False)\n",
    "        L1loss = torch.nn.L1Loss()\n",
    "        test_loss = 0.0\n",
    "        test_mae = 0.0\n",
    "        minibatch_num = 0\n",
    "        #\n",
    "        # your code here (mae = mean absolute error)\n",
    "        #\n",
    "        for users, items, label in dataloader:\n",
    "            output = self._net(users.to(self._device), items.to(self._device))\n",
    "            mae = L1loss(output, label)\n",
    "            loss = self._loss_func(output, label)\n",
    "            \n",
    "            test_loss += loss.cpu().item()\n",
    "            test_mae  += mae.cpu().item()\n",
    "            minibatch_num += 1      \n",
    "        \n",
    "        test_loss = test_loss / (minibatch_num)\n",
    "        test_mae = test_mae / (minibatch_num)\n",
    "        if verbose:\n",
    "            print(f\"RMSE: {np.sqrt(test_loss)}, MAE: {test_mae}\")\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGuzPUNrUUG_"
   },
   "outputs": [],
   "source": [
    "model = FactorizationModel(embedding_dim=50,  # latent dimensionality\n",
    "                                   n_iter=5,  # number of epochs of training\n",
    "                                   learning_rate=5e-4,\n",
    "                                   l2=1e-8,  # strength of L2 regularization\n",
    "                                   num_users=total_user_id,\n",
    "                                   num_items=total_item_id,\n",
    "                                   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for user,item, label in train_dataloader:\n",
    "    print(user.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Bd2CIosUUHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss_train 0.8420454224552771, loss_val 0.8758383989334106\n",
      "Epoch 1: loss_train 0.841398860092717, loss_val 0.8653251528739929\n",
      "Epoch 2: loss_train 0.8403925844515213, loss_val 0.8735279440879822\n",
      "Epoch 3: loss_train 0.8399388290414906, loss_val 0.8609673380851746\n",
      "Epoch 4: loss_train 0.8391016723983216, loss_val 0.8559385538101196\n",
      "CPU times: user 33.2 s, sys: 121 ms, total: 33.3 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKyc7Bg5UUHR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9206910512105997, MAE: 0.7284607893350173\n"
     ]
    }
   ],
   "source": [
    "_= model.test(test_dataloader,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXVIF75IUUHW"
   },
   "source": [
    "Play with the parameter to beat the benchmarks presented here: [Surprise](https://github.com/NicolasHug/Surprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VK3KgG47V1Di"
   },
   "source": [
    "## 4. Best and worst movies\n",
    "\n",
    "Now you need to rank the movies according to their bias. For this, you need to recover the biases of the movies, make a list of the pairs `[name of the movie, its bias]` and then sort this list according to the biases. You can use the method sort of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KDDTQfxV1Di"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dc1ZKW9XV1Dl"
   },
   "source": [
    "## 5. PCA of movies' embeddings\n",
    "\n",
    "Now you can also plpay with the embeddings learned by your algorithm for the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HX37hFDsV1Dl"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWomt-l-V1Dp"
   },
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": false,
   "name": "08_collaborative_filtering_1M.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
