{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "8TOhzssTBZAb"
   },
   "source": [
    "# Finding Synonyms and Analogies\n",
    "\n",
    "This notebook is taken from a [PyTorch NLP tutorial](https://github.com/joosthub/pytorch-nlp-tutorial-ny2018/blob/master/day_1/0_Using_Pretrained_Embeddings.ipynb) source: [repository for the training tutorial as the 2018 O'Reilly AI Conference in NYC on April 29 and 30, 2018](https://github.com/joosthub/pytorch-nlp-tutorial-ny2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colab SETUP\n",
    "#!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhJ0hUC5BZAe"
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import notebook\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhHjwm2JBZAl"
   },
   "source": [
    "Glove embeddings can be downloaded from [GloVe webpage](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "You need to uncomment the appropriate part in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f76c_EM1Ch3q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'ROOT_DIR'\n",
      "/spc/home/andy/00_workspace/dl/notebooks/Module8\n",
      "--2023-05-09 20:29:41--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.03MB/s    in 2m 46s  \n",
      "\n",
      "2023-05-09 20:32:27 (4.96 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "## Colab SETUP\n",
    "# #!mkdir data\n",
    "# #%cd data\n",
    "# ROOT_DIR = '/home/andy/00_workspace/dl/data/08/content'\n",
    "# %cd $ROOT_DIR\n",
    "# !wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "# !unzip glove.6B.zip\n",
    "\n",
    "## local SETUP download glove in ~/data/ with the commands wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "## and unzip glove.6B.zip\n",
    "#ROOT_DIR = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWUdh2BxBZAn"
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(ROOT_DIR,'data/')\n",
    "file = 'glove.6B.100d.txt'\n",
    "glove_filename=data_path+file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GX0hecoBZAr"
   },
   "outputs": [],
   "source": [
    "def load_word_vectors(filename):\n",
    "    word_to_index = {}\n",
    "    word_vectors = []\n",
    "    \n",
    "    with open(filename) as fp:\n",
    "        for line in notebook.tqdm(fp.readlines(), leave=False):\n",
    "            line = line.split(\" \")\n",
    "            \n",
    "            word = line[0]\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            \n",
    "            vec = np.array([float(x) for x in line[1:]])\n",
    "            word_vectors.append(vec)\n",
    "            \n",
    "    return word_to_index, word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDUMIr66BZAz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc409e71b6a43bab8cbc5f93b803ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_to_index, word_vectors = load_word_vectors(glove_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvIOgxSRBZA8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iaYd15JBZBB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlkJErGvBZBG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3K8WuWEBZBL"
   },
   "outputs": [],
   "source": [
    "class PreTrainedEmbeddings(object):\n",
    "    def __init__(self, glove_filename):\n",
    "        self.word_to_index, self.word_vectors = load_word_vectors(glove_filename)\n",
    "        self.word_vector_size = len(self.word_vectors[0])\n",
    "        \n",
    "        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n",
    "        # annoyindex: 基于内存的索引，用于快速相似度检索\n",
    "        # 以欧几里得距离为度量，构建50棵树\n",
    "        self.index = AnnoyIndex(self.word_vector_size, metric='euclidean')\n",
    "        print('Building Index')\n",
    "        for _, i in notebook.tqdm(self.word_to_index.items(), leave=False):\n",
    "            self.index.add_item(i, self.word_vectors[i])\n",
    "        self.index.build(50)\n",
    "        print('Finished!')\n",
    "    \n",
    "    def get_embedding(self, word):\n",
    "        return self.word_vectors[self.word_to_index[word]]\n",
    "    \n",
    "    def closest(self, word, n=1):\n",
    "        vector = self.get_embedding(word)\n",
    "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
    "        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
    "    \n",
    "    def closest_v(self, vector, n=1):\n",
    "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
    "        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
    "    \n",
    "    def sim(self, w1, w2):\n",
    "        return np.dot(self.get_embedding(w1), self.get_embedding(w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZzQW7pyBZBP"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b3c42f6a5a4ebc8a09fb1c1fe57721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Index\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff388e5e618540b8a9c7ca702c55d856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "glove = PreTrainedEmbeddings(glove_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Stpp4FNaBZBT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'microsoft', 'dell', 'ibm', 'intel']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.closest('apple', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARYYKOwcBZBa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chip', 'chips', 'semiconductor', 'intel', 'tech']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.closest('chip', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0-ywu08BZBe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baby', 'babies', 'boy', 'girl', 'infant']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.closest('baby', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtS8hOuPBZBm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful', 'lovely', 'wonderful', 'charming', 'elegant']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.closest('beautiful', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhPAEA5lBZBs"
   },
   "outputs": [],
   "source": [
    "def SAT_analogy(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = glove.get_embedding(w1)\n",
    "        w2v = glove.get_embedding(w2)\n",
    "        w3v = glove.get_embedding(w3)\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = glove.closest_v(w4v, n=5)\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlxpUPIhBZBw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : he :: woman : she\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('man', 'he', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07UCvv3fBZB4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly : plane :: sail : ship\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('fly', 'plane', 'sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOHAs9gIBZB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beijing : china :: tokyo : japan\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('beijing', 'china', 'tokyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdpkkLgNBZCC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : woman :: son : daughter\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('man', 'woman', 'son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M019lyRbBZCH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : doctor :: woman : nurse\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('man', 'doctor', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dmuw3B3zBZCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman : leader :: man : leaders\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('woman', 'leader', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pen : write :: book : books\n"
     ]
    }
   ],
   "source": [
    "SAT_analogy('pen', 'write', 'book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeWK5ASVBZCP"
   },
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": false,
   "name": "08_Playing_with_word_embedding.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
