{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 5](https://dataflowr.github.io/website/modules/5-stacking-layers/): overfitting a MLP on CIFAR10\n",
    "\n",
    "Training loop over CIFAR10 (40,000 train images, 10,000 test images). What happens if you\n",
    "- switch the training to a GPU? Is it faster?\n",
    "- Remove the `ReLU()`? \n",
    "- Increase the learning rate?\n",
    "- Stack more layers? \n",
    "- Perform more epochs?\n",
    "\n",
    "Can you completely overfit the training set (i.e. get 100% accuracy?)\n",
    "\n",
    "This code is highly non-modulable. Create functions for each specific task. \n",
    "(hint: see [this](https://github.com/pytorch/examples/blob/master/mnist/main.py))\n",
    "\n",
    "Your training went well. Good. Why not save the weights of the network (`net.state_dict()`) using `torch.save()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/andy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db065602b72c4a94b6c87302075da027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n",
      "Files already downloaded and verified\n",
      "Epoch 0\n",
      "Train loss 0.0347, Train accuracy 18.89%\n",
      "Train loss 0.0295, Train accuracy 32.67%\n",
      "Train loss 0.0282, Train accuracy 36.32%\n",
      "Train loss 0.0274, Train accuracy 38.15%\n",
      "Train loss 0.0267, Train accuracy 39.69%\n",
      "Train loss 0.0263, Train accuracy 40.52%\n",
      "Train loss 0.0261, Train accuracy 41.25%\n",
      "Train loss 0.0258, Train accuracy 41.85%\n",
      "Epoch 1\n",
      "Train loss 0.0229, Train accuracy 48.72%\n",
      "Train loss 0.0229, Train accuracy 49.42%\n",
      "Train loss 0.0229, Train accuracy 49.13%\n",
      "Train loss 0.0228, Train accuracy 49.33%\n",
      "Train loss 0.0225, Train accuracy 49.60%\n",
      "Train loss 0.0225, Train accuracy 49.86%\n",
      "Train loss 0.0224, Train accuracy 49.90%\n",
      "Train loss 0.0224, Train accuracy 50.12%\n",
      "Epoch 2\n",
      "Train loss 0.0209, Train accuracy 53.84%\n",
      "Train loss 0.0212, Train accuracy 53.58%\n",
      "Train loss 0.0212, Train accuracy 53.29%\n",
      "Train loss 0.0211, Train accuracy 53.65%\n",
      "Train loss 0.0209, Train accuracy 53.76%\n",
      "Train loss 0.0208, Train accuracy 54.00%\n",
      "Train loss 0.0208, Train accuracy 53.96%\n",
      "Train loss 0.0208, Train accuracy 54.04%\n",
      "End of training.\n",
      "\n",
      "End of testing. Test accuracy 50.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as t\n",
    "\n",
    "# define network structure \n",
    "net = nn.Sequential(nn.Linear(3 * 32 * 32, 1000), nn.ReLU(), nn.Linear(1000, 10))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "# load data\n",
    "to_tensor =  t.ToTensor()\n",
    "normalize = t.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "flatten =  t.Lambda(lambda x:x.view(-1))\n",
    "\n",
    "transform_list = t.Compose([to_tensor, normalize, flatten])\n",
    "train_set = torchvision.datasets.CIFAR10(root='.', train=True, transform=transform_list, download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root='.', train=False, transform=transform_list, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
    "\n",
    "# === Train === ###\n",
    "net.train()\n",
    "\n",
    "# train loop\n",
    "for epoch in range(3):\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    \n",
    "    # loop per epoch \n",
    "    for i, (batch, targets) in enumerate(train_loader):\n",
    "\n",
    "        output = net(batch)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        train_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "        train_loss += loss\n",
    "\n",
    "        if i % 100 == 10: print('Train loss {:.4f}, Train accuracy {:.2f}%'.format(\n",
    "            train_loss / ((i+1) * 64), 100 * train_correct / ((i+1) * 64)))\n",
    "        \n",
    "print('End of training.\\n')\n",
    "    \n",
    "# === Test === ###\n",
    "test_correct = 0\n",
    "net.eval()\n",
    "\n",
    "# loop, over whole test set\n",
    "for i, (batch, targets) in enumerate(test_loader):\n",
    "    \n",
    "    output = net(batch)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    test_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "    \n",
    "print('End of testing. Test accuracy {:.2f}%'.format(\n",
    "    100 * test_correct / (len(test_loader) * 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointers are everywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4386, -0.2717],\n",
      "        [ 0.3115, -0.4501]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4463, -0.2791],\n",
      "        [ 0.3037, -0.4575]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Linear(2, 2)\n",
    "w = net.weight\n",
    "print(w)\n",
    "\n",
    "x = torch.rand(1, 2)\n",
    "y = net(x).sum()\n",
    "y.backward()\n",
    "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2142, -0.5144],\n",
      "        [-0.0849, -0.4394]], grad_fn=<CloneBackward0>)\n",
      "tensor([[ 0.2142, -0.5144],\n",
      "        [-0.0849, -0.4394]], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Linear(2, 2)\n",
    "w = net.weight.clone()\n",
    "print(w)\n",
    "\n",
    "x = torch.rand(1, 2)\n",
    "y = net(x).sum()\n",
    "y.backward()\n",
    "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0755, -0.3740],\n",
      "        [-0.3685, -0.6943]])\n",
      "tensor([[-0.0755, -0.3740],\n",
      "        [-0.3685, -0.6943]])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "net[0].weight = net[1].weight  # weight sharing\n",
    "\n",
    "x = torch.rand(1, 2)\n",
    "y = net(x).sum()\n",
    "y.backward()\n",
    "print(net[0].weight.grad)\n",
    "print(net[1].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
